{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7688c1aa",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3105f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import preprocessing functions\n",
    "from preprocess import preprocess_text, preprocess_skills_column\n",
    "\n",
    "# Import ML libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adbd44f",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../dataset/skills_dataset.csv')\n",
    "print(f\"Dataset loaded: {df.shape[0]} records, {df.shape[1]} columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0865b150",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show original skills examples\n",
    "print(\"Original Skills (sample):\")\n",
    "print(df['skills'].head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d859492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to skills column\n",
    "df['skills_clean'] = df['skills'].apply(preprocess_text)\n",
    "print(\"Preprocessing completed!\")\n",
    "print(\"\\nCleaned Skills (sample):\")\n",
    "print(df['skills_clean'].head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c6df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs cleaned\n",
    "comparison = pd.DataFrame({\n",
    "    'Original': df['skills'].head(10),\n",
    "    'Cleaned': df['skills_clean'].head(10)\n",
    "})\n",
    "print(\"Before and After Preprocessing:\")\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfae8b7",
   "metadata": {},
   "source": [
    "## 4. TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13365bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=100,  # Limit to top 100 features\n",
    "    ngram_range=(1, 2),  # Use unigrams and bigrams\n",
    "    min_df=1,  # Minimum document frequency\n",
    "    max_df=0.8  # Maximum document frequency (ignore very common terms)\n",
    ")\n",
    "\n",
    "print(\"TF-IDF Vectorizer initialized\")\n",
    "print(f\"Configuration: max_features=100, ngram_range=(1,2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6601562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the cleaned skills\n",
    "X = tfidf.fit_transform(df['skills_clean'])\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4bdd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "print(f\"\\nTotal features extracted: {len(feature_names)}\")\n",
    "print(f\"\\nFirst 20 features:\")\n",
    "print(feature_names[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for better visualization\n",
    "X_df = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "print(\"\\nFeature matrix (first 5 rows, first 10 features):\")\n",
    "X_df.iloc[:5, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c879ebe",
   "metadata": {},
   "source": [
    "## 5. Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dcdf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Label Encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode target variable\n",
    "y = label_encoder.fit_transform(df['job_role'])\n",
    "\n",
    "print(f\"Target variable encoded: {len(y)} labels\")\n",
    "print(f\"Number of unique classes: {len(label_encoder.classes_)}\")\n",
    "print(f\"\\nClass labels: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show encoding mapping\n",
    "encoding_map = pd.DataFrame({\n",
    "    'Job Role': label_encoder.classes_,\n",
    "    'Encoded Label': range(len(label_encoder.classes_))\n",
    "})\n",
    "print(\"\\nJob Role to Label Mapping:\")\n",
    "encoding_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0657c0",
   "metadata": {},
   "source": [
    "## 6. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd247ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y  # Maintain class distribution\n",
    ")\n",
    "\n",
    "print(\"Data split completed!\")\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "print(f\"Feature dimensions: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29676535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution in train and test sets\n",
    "print(\"Training set class distribution:\")\n",
    "train_dist = pd.Series(y_train).value_counts().sort_index()\n",
    "print(train_dist)\n",
    "\n",
    "print(\"\\nTesting set class distribution:\")\n",
    "test_dist = pd.Series(y_test).value_counts().sort_index()\n",
    "print(test_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c85d5f",
   "metadata": {},
   "source": [
    "## 7. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ad6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze top features\n",
    "feature_importance = np.asarray(X.sum(axis=0)).flatten()\n",
    "feature_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Total Score': feature_importance\n",
    "}).sort_values('Total Score', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "feature_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09187bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 15 features\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_features = feature_df.head(15)\n",
    "plt.barh(top_features['Feature'], top_features['Total Score'], color='teal')\n",
    "plt.xlabel('TF-IDF Score (Sum)', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 15 Most Important Features (TF-IDF)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce75e8a",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ecfa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics\n",
    "summary = {\n",
    "    'Total Samples': len(df),\n",
    "    'Total Features': X.shape[1],\n",
    "    'Number of Classes': len(label_encoder.classes_),\n",
    "    'Training Samples': X_train.shape[0],\n",
    "    'Testing Samples': X_test.shape[0],\n",
    "    'Feature Matrix Sparsity': f\"{(1 - X.nnz / (X.shape[0] * X.shape[1])) * 100:.2f}%\"\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key:.<30} {value}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573982d",
   "metadata": {},
   "source": [
    "## 9. Save Feature Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639cc37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory if it doesn't exist\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "# Save feature information to file\n",
    "with open('../results/feature_info.txt', 'w') as f:\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(\"FEATURE ENGINEERING SUMMARY - DAY 2\\n\")\n",
    "    f.write(\"Student Skill Gap Analyzer & Career Recommendation System\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"DATASET INFORMATION:\\n\")\n",
    "    f.write(\"-\" * 60 + \"\\n\")\n",
    "    f.write(f\"Total Samples: {len(df)}\\n\")\n",
    "    f.write(f\"Number of Job Roles: {len(label_encoder.classes_)}\\n\")\n",
    "    f.write(f\"Job Roles: {', '.join(label_encoder.classes_)}\\n\\n\")\n",
    "    \n",
    "    f.write(\"FEATURE EXTRACTION (TF-IDF):\\n\")\n",
    "    f.write(\"-\" * 60 + \"\\n\")\n",
    "    f.write(f\"Total Features Extracted: {X.shape[1]}\\n\")\n",
    "    f.write(f\"Max Features Limit: 100\\n\")\n",
    "    f.write(f\"N-gram Range: (1, 2)\\n\")\n",
    "    f.write(f\"Feature Matrix Shape: {X.shape}\\n\")\n",
    "    f.write(f\"Sparsity: {(1 - X.nnz / (X.shape[0] * X.shape[1])) * 100:.2f}%\\n\\n\")\n",
    "    \n",
    "    f.write(\"TRAIN-TEST SPLIT:\\n\")\n",
    "    f.write(\"-\" * 60 + \"\\n\")\n",
    "    f.write(f\"Training Samples: {X_train.shape[0]}\\n\")\n",
    "    f.write(f\"Testing Samples: {X_test.shape[0]}\\n\")\n",
    "    f.write(f\"Test Size: 20%\\n\")\n",
    "    f.write(f\"Random State: 42\\n\")\n",
    "    f.write(f\"Stratified: Yes\\n\\n\")\n",
    "    \n",
    "    f.write(\"TOP 20 FEATURES:\\n\")\n",
    "    f.write(\"-\" * 60 + \"\\n\")\n",
    "    for idx, row in feature_df.head(20).iterrows():\n",
    "        f.write(f\"{row['Feature']:.<40} {row['Total Score']:.4f}\\n\")\n",
    "\n",
    "print(\"Feature information saved to: ../results/feature_info.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1607654c",
   "metadata": {},
   "source": [
    "## 10. Key Observations\n",
    "\n",
    "**Preprocessing Achievements:**\n",
    "- Successfully cleaned skill text (lowercase, removed special characters, normalized spacing)\n",
    "- Converted text data to numerical features using TF-IDF\n",
    "- Encoded job roles as numerical labels\n",
    "\n",
    "**Feature Engineering Results:**\n",
    "- Extracted meaningful features representing skills and technologies\n",
    "- Created sparse feature matrix suitable for machine learning\n",
    "- Maintained class distribution through stratified splitting\n",
    "\n",
    "**Next Steps (Day 3):**\n",
    "1. Build baseline classification models\n",
    "2. Evaluate model performance\n",
    "3. Experiment with different algorithms\n",
    "4. Fine-tune hyperparameters"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
